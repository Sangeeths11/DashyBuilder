{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('..\\\\dashboards\\\\Iris.xls')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\csang\\miniconda3\\envs\\fhgr\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from llama_index.core.readers.json import JSONReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def return_vals(df, c):\n",
    "    if isinstance(df[c].iloc[0], (int, float, complex)):\n",
    "        return [max(df[c]), min(df[c]), np.mean(df[c])]\n",
    "    elif isinstance(df[c].iloc[0], datetime.datetime):\n",
    "        return [str(max(df[c])), str(min(df[c]))]\n",
    "    else:\n",
    "        return df[c].value_counts().nlargest(10).to_dict()\n",
    "\n",
    "dict_ = {}\n",
    "for c in df.columns:\n",
    "    dict_[c] = {'column_name': c, 'type': str(type(df[c].iloc[0])), 'variable_information': return_vals(df, c)}\n",
    "\n",
    "with open(\"dataframe.json\", \"w\") as fp:\n",
    "    json.dump(dict_, fp)\n",
    "\n",
    "reader = JSONReader()\n",
    "documents = reader.load_data(input_file='dataframe.json')\n",
    "\n",
    "dataframe_index = VectorStoreIndex.from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "styling_instructions =[Document(text=\"\"\"\n",
    "  Dont ignore any of these instructions.\n",
    "        For a line chart always use plotly_white template, reduce x axes & y axes line to 0.2 & x & y grid width to 1. \n",
    "        Always give a title and make bold using html tag axis label and try to use multiple colors if more than one line\n",
    "        Annotate the min and max of the line\n",
    "        Display numbers in thousand(K) or Million(M) if larger than 1000/100000 \n",
    "        Show percentages in 2 decimal points with '%' sign\n",
    "        \"\"\"\n",
    "        )\n",
    "        , Document(text=\"\"\"\n",
    "        Dont ignore any of these instructions.\n",
    "        For a bar chart always use plotly_white template, reduce x axes & y axes line to 0.2 & x & y grid width to 1. \n",
    "        Always give a title and make bold using html tag axis label and try to use multiple colors if more than one line\n",
    "        Always display numbers in thousand(K) or Million(M) if larger than 1000/100000. Add annotations x values\n",
    "        Annotate the values on the y variable\n",
    "        If variable is a percentage show in 2 decimal points with '%' sign.\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "       # You should fill in instructions for other charts and play around with these instructions\n",
    "       , Document(text=\n",
    "          \"\"\" General chart instructions\n",
    "        Do not ignore any of these instructions\n",
    "         always use plotly_white template, reduce x & y axes line to 0.2 & x & y grid width to 1. \n",
    "        Always give a title and make bold using html tag axis label \n",
    "        Always display numbers in thousand(K) or Million(M) if larger than 1000/100000. Add annotations x values\n",
    "        If variable is a percentage show in 2 decimal points with '%'\"\"\")\n",
    "         ]\n",
    "# Creating an Index\n",
    "style_index =  VectorStoreIndex.from_documents(styling_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x1a7bce179a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.llms.groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groqkey=os.environ.get('GROQ_API_KEY')\n",
    "llm = Groq(model=\"llama3-70b-8192\", api_key=groqkey)\n",
    "\n",
    "# Build query engines over your indexes\n",
    "styling_engine = style_index.as_query_engine(similarity_top_k=1, llm=llm)\n",
    "dataframe_engine = dataframe_index.as_query_engine(similarity_top_k=1, llm=llm)\n",
    "\n",
    "\n",
    "# Builds the tools\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=dataframe_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"dataframe_index\",\n",
    "            description=\"Provides information about the data in the data frame. Only use column names in this tool\",\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=styling_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"Styling\",\n",
    "            description=\"Provides instructions on how to style your Plotly plots. Use a detailed plain text question as input to the tool.\",\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Use only Groq model\n",
    "\n",
    "\n",
    "# Initialize ReAct agent\n",
    "agent = ReActAgent.from_tools(query_engine_tools, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "new_prompt_txt= \"\"\"You are designed to help with building data visualizations in Plotly. You may do all sorts of analyses and actions using Python\n",
    "\n",
    "## Tools\n",
    "\n",
    "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
    "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
    "\n",
    "You have access to the following tools, use these tools to find information about the data and styling:\n",
    "{tool_desc}\n",
    "\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Please answer in the same language as the question and use the following format:\n",
    "\n",
    "```\n",
    "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
    "Action: tool name (one of {tool_names}) if using a tool.\n",
    "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
    "```\n",
    "\n",
    "Please ALWAYS start with a Thought.\n",
    "\n",
    "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
    "\n",
    "If this format is used, the user will respond in the following format:\n",
    "\n",
    "```\n",
    "Observation: tool response\n",
    "```\n",
    "\n",
    "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
    "\n",
    "```\n",
    "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
    "Answer: [your answer here (In the same language as the user's question)]\n",
    "```\n",
    "\n",
    "```\n",
    "Thought: I cannot answer the question with the provided tools.\n",
    "Answer: [your answer here (In the same language as the user's question)]\n",
    "```\n",
    "\n",
    "## Current Conversation\n",
    "\n",
    "Below is the current conversation consisting of interleaving human and assistant messages.\"\"\"\n",
    "\n",
    "# Adding the prompt text into PromptTemplate object\n",
    "new_prompt = PromptTemplate(new_prompt_txt)\n",
    "\n",
    "# Updating the prompt\n",
    "agent.update_prompts({'agent_worker:system_prompt':new_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 939dd3aa-42b2-4d03-b75a-a7478a4dad8b. Step input: Give Plotly code for a bar chart for the column SepalLengthCm , Species\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Python. I need to use a tool to help me answer the question.\n",
      "Action: dataframe_index\n",
      "Action Input: {'input': 'SepalLengthCm, Species'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: SepalLengthCm is a floating-point number and Species is a string.\n",
      "\u001b[0m> Running step c10e81ce-5919-4e08-9899-df6b6804a673. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have the information about the columns. Now I need to provide the Plotly code for a bar chart.\n",
      "Here is the Plotly code for a bar chart for the column SepalLengthCm, Species:\n",
      "\n",
      "```\n",
      "import plotly.express as px\n",
      "\n",
      "fig = px.bar(df, x='Species', y='SepalLengthCm')\n",
      "fig.update_layout(template='plotly_white', title='<b>Sepal Length by Species</b>')\n",
      "fig.show()\n",
      "```\n",
      "\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The above code will generate a bar chart where the x-axis represents the Species and the y-axis represents the SepalLengthCm.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Give Plotly code for a bar chart for the column SepalLengthCm , Species\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhgr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
